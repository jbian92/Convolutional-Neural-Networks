{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cat_vs_Dog_Image_Model.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNdwS1rdVLRnVvwEz8IWQwq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jbian92/Convolutional-Neural-Networks/blob/main/Cat_vs_Dog_Image_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6onwjNh8VwJ"
      },
      "source": [
        "Download the image dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cBKJUDI8NLM"
      },
      "source": [
        "! wget https://www.ocf.berkeley.edu/~mingjie/tr/mnist/animals.zip\n",
        "! unzip animals.zip\n",
        "! rm animals.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2omGunx-t9o"
      },
      "source": [
        "**Plan:** \n",
        "1. Convert images from the dataset into black and white\n",
        "2. Create a model that can predict if a black and white image is of a cat or dog"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUkeFGr1-qF_"
      },
      "source": [
        "from sklearn.model_selection import train_test_split                    # used to split data into a training dataset and testing dataset\n",
        "from tensorflow import keras                                            # used to create machine learning models and train them\n",
        "from keras.models import Sequential                                     # used to create a base sequential model because CNN is a sequential model\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D  # used to create CNN architecture\n",
        "from PIL import Image                                                   # used to process images\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USq6r3Pu_HTx"
      },
      "source": [
        "images = []\n",
        "labels = []\n",
        "\n",
        "for i in range(1,4900):\n",
        "  catpath = f'cat/flickr_cat_{i:06}.jpg'\n",
        "  dogpath = f'dog/flickr_dog_{i:06}.jpg'\n",
        "\n",
        "  try:\n",
        "    with Image.open(catpath) as im_cat:     # opens the image\n",
        "      im_cat = im_cat.convert(\"L\")          # converts the image to be black and white\n",
        "      catpix = np.array(im_cat.getdata())\n",
        "      catpix = catpix.reshape(512, 512, 1)\n",
        "      images.append(catpix)                 # image gets added onto images \n",
        "      labels.append(np.array([1,0]))        # one hot encoded version of the label gets added onto labels\n",
        "  except:\n",
        "    continue\n",
        "\n",
        "  try:\n",
        "    with Image.open(dogpath) as im_dog:\n",
        "      im_dog = im_dog.convert(\"L\")\n",
        "      dogpix = np.array(im_dog.getdata())\n",
        "      dogpix = dogpix.reshape(512, 512, 1)\n",
        "      images.append(dogpix)\n",
        "      labels.append(np.array([0,1]))\n",
        "  except:\n",
        "    continue\n",
        "\n",
        "  x = np.stack(images)\n",
        "  y = np.stack(labels)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9k-O52IAmjD"
      },
      "source": [
        "Define constants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSTajeMAAtjU"
      },
      "source": [
        "batch_size = 16                # how many images get sent to the model at a time when training\n",
        "num_classes = 2                # number of total classifications (cat or dog)\n",
        "epochs = 12                    # number of times the model will see the entire training dataset"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gpi_3kEBFMv"
      },
      "source": [
        "Create training and testing sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7-rVZ4iBHAf"
      },
      "source": [
        "# X_train represents training evidence\n",
        "# X_test represents testing evidence\n",
        "# y_train represents training labels\n",
        "# y_test represents testing labels\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1o0MYJHBdp4"
      },
      "source": [
        "Set up the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAAmAsYfBe8i"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "# add convolution layers, pooling layers, and dropout layers with fully connected layers at the end\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=(512,512,1)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.15))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.15))\n",
        "model.add(Dense(num_classes, activation='softmax'))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZhRZ2qHB6re"
      },
      "source": [
        "Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqE11VV0B7iA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "415d120e-7861-4be3-dea6-1fa4b7e350c4"
      },
      "source": [
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adadelta(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/12\n",
            "61/61 [==============================] - 97s 2s/step - loss: 0.6280 - accuracy: 0.7541 - val_loss: 0.4826 - val_accuracy: 0.8101\n",
            "Epoch 2/12\n",
            "61/61 [==============================] - 92s 2s/step - loss: 0.5014 - accuracy: 0.7802 - val_loss: 0.4722 - val_accuracy: 0.8173\n",
            "Epoch 3/12\n",
            "61/61 [==============================] - 92s 2s/step - loss: 0.4337 - accuracy: 0.7648 - val_loss: 0.4249 - val_accuracy: 0.8125\n",
            "Epoch 4/12\n",
            "61/61 [==============================] - 92s 2s/step - loss: 0.4269 - accuracy: 0.8135 - val_loss: 0.4779 - val_accuracy: 0.8005\n",
            "Epoch 5/12\n",
            "61/61 [==============================] - 96s 2s/step - loss: 0.4207 - accuracy: 0.8090 - val_loss: 0.4735 - val_accuracy: 0.8005\n",
            "Epoch 6/12\n",
            "61/61 [==============================] - 96s 2s/step - loss: 0.4639 - accuracy: 0.7980 - val_loss: 0.4191 - val_accuracy: 0.8269\n",
            "Epoch 7/12\n",
            "61/61 [==============================] - 92s 2s/step - loss: 0.4350 - accuracy: 0.8189 - val_loss: 0.4050 - val_accuracy: 0.8365\n",
            "Epoch 8/12\n",
            "61/61 [==============================] - 96s 2s/step - loss: 0.3095 - accuracy: 0.8561 - val_loss: 0.3945 - val_accuracy: 0.8486\n",
            "Epoch 9/12\n",
            "61/61 [==============================] - 92s 2s/step - loss: 0.5228 - accuracy: 0.7933 - val_loss: 0.4571 - val_accuracy: 0.8269\n",
            "Epoch 10/12\n",
            "61/61 [==============================] - 96s 2s/step - loss: 0.3148 - accuracy: 0.8771 - val_loss: 0.4284 - val_accuracy: 0.8269\n",
            "Epoch 11/12\n",
            "61/61 [==============================] - 92s 2s/step - loss: 0.3298 - accuracy: 0.8423 - val_loss: 0.3956 - val_accuracy: 0.8510\n",
            "Epoch 12/12\n",
            "61/61 [==============================] - 92s 2s/step - loss: 0.3443 - accuracy: 0.8185 - val_loss: 0.3812 - val_accuracy: 0.8486\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7efc5adf59d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2e7KIOpxB_bU"
      },
      "source": [
        "Test the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1d7_b_5CAeY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12203b3a-834c-45a9-cf4b-9021ac2a5a48"
      },
      "source": [
        "model.evaluate(X_test, y_test, verbose=2)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13/13 - 5s - loss: 0.3812 - accuracy: 0.8486\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.381220281124115, 0.848557710647583]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    }
  ]
}